<Section: TRAINING>
Logging to /tmp/openai-2020-09-30-14-54-28-436994
Creating dummy env object to get spaces
(None, None)
/usr/local/lib/python3.8/dist-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
(None, None)
reset
cur_obs [ 62   0   0   0   0  30 833  84  62   0  18   3]
max_step 26 num_step 0
reward 0
(48,) 0 False {}
cur_obs [ 95   8   9   0   0  60 714 134 112  21   3  16]
max_step 26 num_step 1
reward 0
(48,) 0 False {}
cur_obs [ 38   4   8  39  23  90 625 168 112  24   0  71]
max_step 26 num_step 2
reward 0
(48,) 0 False {}
cur_obs [122   0   0  11   0 120 570  66 133   2  71 158]
max_step 26 num_step 3
reward 0
(48,) 0 False {}
cur_obs [ 92  15  10   0   0 150 535 101 117  22  13 212]
max_step 26 num_step 4
reward 0
(48,) 0 False {}
cur_obs [ 62  13   6   0   0 180 496 104  81  14  17 288]
max_step 26 num_step 5
reward 0
(48,) 0 False {}
cur_obs [ 48  11   7   0   0 210 454  91  66   0  20 369]
max_step 26 num_step 6
reward 0
(48,) 0 False {}
cur_obs [ 33   6   5   0   0 240 410  88  44  16  14 428]
max_step 26 num_step 7
reward 0
(48,) 0 False {}
cur_obs [ 29   5   2   0   0 270 351  83  36  10  23 497]
max_step 26 num_step 8
reward 0
(48,) 0 False {}
cur_obs [ 30  12   8   0   0 300 273  96  50  10  19 552]
max_step 26 num_step 9
reward 0
(48,) 0 False {}
cur_obs [ 33   1   3   0   0 330 205 115  37  15  22 606]
max_step 26 num_step 10
reward 0
(48,) 0 False {}
cur_obs [ 38   5   9   0   0 360 134 108  52  13  23 670]
max_step 26 num_step 11
reward 0
(48,) 0 False {}
cur_obs [ 33   7   4   0   0 390  93  87  44   8  32 736]
max_step 26 num_step 12
reward 0
(48,) 0 False {}
cur_obs [ 21  14   6   0   0 420  48  83  41   0  32 796]
max_step 26 num_step 13
reward 0
(48,) 0 False {}
cur_obs [ 14   6   6   0   0 450  30  63  26   8  27 846]
max_step 26 num_step 14
reward 0
(48,) 0 False {}
cur_obs [ 10   5   4   0   0 480  11  47  19   6  20 897]
max_step 26 num_step 15
reward 0
(48,) 0 False {}
cur_obs [  3   3   3   0   0 510   5  21   9   5  19 941]
max_step 26 num_step 16
reward 0
(48,) 0 False {}
cur_obs [  2   0   0   0   0 540   2  24   2   0   9 963]
max_step 26 num_step 17
reward 0
(48,) 0 False {}
cur_obs [  1   0   0   0   0 570   1  12   1   1   8 977]
max_step 26 num_step 18
reward 0
(48,) 0 False {}
cur_obs [  1   0   1   0   0 600   0   3   2   0   7 988]
max_step 26 num_step 19
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 630   0   2   0   0   7 991]
max_step 26 num_step 20
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 660   0   0   0   0   7 993]
max_step 26 num_step 21
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 690   0   0   0   0   7 993]
max_step 26 num_step 22
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 720   0   0   0   0   7 993]
max_step 26 num_step 23
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 750   0   0   0   0   7 993]
max_step 26 num_step 24
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 780   0   0   0   0   7 993]
max_step 26 num_step 25
reward 0
(48,) 0 True {'episode': {'r': 0}, 'events': [], 'env_id': 0}
reset
reset
cur_obs [  0   0  12  35   0  30 833 102  47   0  10   8]
max_step 26 num_step 0
reward 0
(48,) 0 False {}
cur_obs [  0   0   8  53  41  60 714 111 102  25   5  43]
max_step 26 num_step 1
reward 0
(48,) 0 False {}
cur_obs [  0   0  17  47  36  90 625 121 100  25  21 108]
max_step 26 num_step 2
reward 0
(48,) 0 False {}
cur_obs [ 54   4   3   0   0 120 570 153  61  15   0 201]
max_step 26 num_step 3
reward 0
(48,) 0 False {}
cur_obs [ 63   6   7   0   0 150 535  93  76  19   8 269]
max_step 26 num_step 4
reward 0
(48,) 0 False {}
cur_obs [ 53   3   7   0   0 180 496  84  63   9  10 338]
max_step 26 num_step 5
reward 0
(48,) 0 False {}
cur_obs [ 35  11   5   0   0 210 454  83  51   0   6 406]
max_step 26 num_step 6
reward 0
(48,) 0 False {}
cur_obs [ 23   2   5   0   0 240 410  77  30  14  15 454]
max_step 26 num_step 7
reward 0
(48,) 0 False {}
cur_obs [ 15   3   5   0   0 270 351  94  23   7  14 511]
max_step 26 num_step 8
reward 0
(48,) 0 False {}
cur_obs [ 25  12   8   0   0 300 273  87  45  13  15 567]
max_step 26 num_step 9
reward 0
(48,) 0 False {}
cur_obs [ 33   3   5   0   0 330 205 117  41   6  16 615]
max_step 26 num_step 10
reward 0
(48,) 0 False {}
cur_obs [ 38  10   4   0   0 360 134 106  52   9  20 679]
max_step 26 num_step 11
reward 0
(48,) 0 False {}
cur_obs [ 24   6   1   0   0 390  93  97  31  10  24 745]
max_step 26 num_step 12
reward 0
(48,) 0 False {}
cur_obs [ 22   5   4   0   0 420  48  83  31   0  28 810]
max_step 26 num_step 13
reward 0
(48,) 0 False {}
cur_obs [  8   6   6   0   0 450  30  52  20  10  24 864]
max_step 26 num_step 14
reward 0
(48,) 0 False {}
cur_obs [  8   4   3   0   0 480  11  50  15   6  17 901]
max_step 26 num_step 15
reward 0
(48,) 0 False {}
cur_obs [  3   3   3   0   0 510   5  29   9   3  13 941]
max_step 26 num_step 16
reward 0
(48,) 0 False {}
cur_obs [  3   0   1   0   0 540   2  14   4   2  10 968]
max_step 26 num_step 17
reward 0
(48,) 0 False {}
cur_obs [  1   0   0   0   0 570   1   7   1   1   6 984]
max_step 26 num_step 18
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 600   0   2   0   0   5 993]
max_step 26 num_step 19
reward 0
(48,) 0 False {}
cur_obs [  0   1   0   0   0 630   0   0   1   0   6 993]
max_step 26 num_step 20
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 660   0   1   0   0   6 993]
max_step 26 num_step 21
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 690   0   0   0   0   6 994]
max_step 26 num_step 22
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 720   0   0   0   0   6 994]
max_step 26 num_step 23
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 750   0   0   0   0   6 994]
max_step 26 num_step 24
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 780   0   0   0   0   6 994]
max_step 26 num_step 25
reward 0
(48,) 0 True {'episode': {'r': 0}, 'events': [], 'env_id': 0}
reset
reset
cur_obs [ 14   0  11  18   0  30 833 119  43   0   1   4]
max_step 26 num_step 0
reward 0
(48,) 0 False {}
cur_obs [  0   0  14  44  21  60 714 132  79  25   3  47]
max_step 26 num_step 1
reward 0
(48,) 0 False {}
cur_obs [  0   0   5  52  28  90 625 138  85  25  15 112]
max_step 26 num_step 2
reward 0
(48,) 0 False {}
cur_obs [ 51   5   5   0   0 120 570 141  61  21   0 207]
max_step 26 num_step 3
reward 0
(48,) 0 False {}
cur_obs [ 48   7   8   0   0 150 535 101  63  11   5 285]
max_step 26 num_step 4
reward 0
(48,) 0 False {}
cur_obs [ 36   4   4   0   0 180 496  83  44  11   9 357]
max_step 26 num_step 5
reward 0
(48,) 0 False {}
cur_obs [ 27  10   4   0   0 210 454  83  41   0  11 411]
max_step 26 num_step 6
reward 0
(48,) 0 False {}
cur_obs [ 14   5   4   0   0 240 410  78  23   9  16 464]
max_step 26 num_step 7
reward 0
(48,) 0 False {}
cur_obs [ 11   4   7   0   0 270 351  88  22   8  15 516]
max_step 26 num_step 8
reward 0
(48,) 0 False {}
cur_obs [ 21  13   7   0   0 300 273  95  41  14  16 561]
max_step 26 num_step 9
reward 0
(48,) 0 False {}
cur_obs [ 24   3   7   0   0 330 205 119  34   9  16 617]
max_step 26 num_step 10
reward 0
(48,) 0 False {}
cur_obs [ 34   7   9   0   0 360 134  99  50   7  25 685]
max_step 26 num_step 11
reward 0
(48,) 0 False {}
cur_obs [ 22  10   8   0   0 390  93  95  40   7  28 737]
max_step 26 num_step 12
reward 0
(48,) 0 False {}
cur_obs [ 14  15   6   0   0 420  48  84  35   0  25 808]
max_step 26 num_step 13
reward 0
(48,) 0 False {}
cur_obs [  6   1   4   0   0 450  30  75  11   8  21 855]
max_step 26 num_step 14
reward 0
(48,) 0 False {}
cur_obs [  4   6   1   0   0 480  11  45  11  10  15 908]
max_step 26 num_step 15
reward 0
(48,) 0 False {}
cur_obs [  5   0   3   0   0 510   5  32   8   1  10 944]
max_step 26 num_step 16
reward 0
(48,) 0 False {}
cur_obs [  1   1   1   0   0 540   2  13   3   4   7 971]
max_step 26 num_step 17
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 570   1   7   0   0   6 986]
max_step 26 num_step 18
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 600   0   4   0   0   6 990]
max_step 26 num_step 19
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 630   0   1   0   0   6 993]
max_step 26 num_step 20
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 660   0   0   0   0   6 994]
max_step 26 num_step 21
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 690   0   0   0   0   6 994]
max_step 26 num_step 22
reward 0
(48,) 0(None, None)
reset
cur_obs [  0   0   0  24   8  30 833 102  32  25   4   4]
max_step 26 num_step 0
reward 0
(48,) 0 False {}
cur_obs [ 50   7  10   0   1  60 714 173  68  15   0  30]
max_step 26 num_step 1
reward 0
(48,) 0 False {}
cur_obs [119   9   0   0   0  90 625  70 128   7  94  76]
max_step 26 num_step 2
reward 0
(48,) 0 False {}
cur_obs [105   7  12   0   0 120 570 136 124  27  12 131]
max_step 26 num_step 3
reward 0
(48,) 0 False {}
cur_obs [ 65  10  12   0   0 150 535 126  87  13  18 221]
max_step 26 num_step 4
reward 0
(48,) 0 False {}
cur_obs [ 53  12  11   0   0 180 496  81  76  17  25 305]
max_step 26 num_step 5
reward 0
(48,) 0 False {}
cur_obs [ 43  15   5   0   0 210 454  84  63   0  33 366]
max_step 26 num_step 6
reward 0
(48,) 0 False {}
cur_obs [ 35   3   9   0   0 240 410  87  47   8  26 422]
max_step 26 num_step 7
reward 0
(48,) 0 False {}
cur_obs [ 23   8   8   0   0 270 351  98  39   9  27 476]
max_step 26 num_step 8
reward 0
(48,) 0 False {}
cur_obs [ 32  16   7   0   0 300 273  98  55   8  28 538]
max_step 26 num_step 9
reward 0
(48,) 0 False {}
cur_obs [ 43   4   5   0   0 330 205 101  52  14  33 595]
max_step 26 num_step 10
reward 0
(48,) 0 False {}
cur_obs [ 40   5   6   0   0 360 134 116  51  17  35 647]
max_step 26 num_step 11
reward 0
(48,) 0 False {}
cur_obs [ 25   7   6   0   0 390  93 105  38  11  40 713]
max_step 26 num_step 12
reward 0
(48,) 0 False {}
cur_obs [ 18   8   4   0   0 420  48  99  30   0  41 782]
max_step 26 num_step 13
reward 0
(48,) 0 False {}
cur_obs [ 13   2   5   0   0 450  30  76  20   4  30 840]
max_step 26 num_step 14
reward 0
(48,) 0 False {}
cur_obs [  6   3   1   0   0 480  11  53  10   8  22 896]
max_step 26 num_step 15
reward 0
(48,) 0 False {}
cur_obs [  3   5   2   0   0 510   5  30  10   8  17 930]
max_step 26 num_step 16
reward 0
(48,) 0 False {}
cur_obs [  1   0   1   0   0 540   2  22   2   1  10 963]
max_step 26 num_step 17
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 570   1   9   0   0   9 981]
max_step 26 num_step 18
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 600   0   5   0   0   9 986]
max_step 26 num_step 19
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 630   0   1   0   0   9 990]
max_step 26 num_step 20
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 660   0   0   0   0   9 991]
max_step 26 num_step 21
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 690   0   0   0   0   9 991]
max_step 26 num_step 22
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 720   0   0   0   0   9 991]
max_step 26 num_step 23
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 750   0   0   0   0   9 991]
max_step 26 num_step 24
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 780   0   0   0   0   9 991]
max_step 26 num_step 25
reward 0
(48,) 0 True {'episode': {'r': 0}, 'events': [], 'env_id': 1}
reset
reset
cur_obs [  0   0  21   0   0  30 833  73  21   0  63  10]
max_step 26 num_step 0
reward 0
(48,) 0 False {}
cur_obs [  0   0   6  58  26  60 714 124  90  25   1  46]
max_step 26 num_step 1
reward 0
(48,) 0 False {}
cur_obs [  0   0  14  62  34  90 625 115 110  25  20 105]
max_step 26 num_step 2
reward 0
(48,) 0 False {}
cur_obs [ 63   4   4   6   0 120 570 138  77  17   1 197]
max_step 26 num_step 3
reward 0
(48,) 0 False {}
cur_obs [ 57  14   3   0   0 150 535  96  74  17   8 270]
max_step 26 num_step 4
reward 0
(48,) 0 False {}
cur_obs [ 47   9   5   0   0 180 496  85  61   9  14 335]
max_step 26 num_step 5
reward 0
(48,) 0 False {}
cur_obs [ 34  14   6   0   0 210 454  72  54   0  13 407]
max_step 26 num_step 6
reward 0
(48,) 0 False {}
cur_obs [ 23   3   5   0   0 240 410  89  31   8  10 452]
max_step 26 num_step 7
reward 0
(48,) 0 False {}
cur_obs [ 15   7   3   0   0 270 351  90  25   9  16 509]
max_step 26 num_step 8
reward 0
(48,) 0 False {}
cur_obs [ 25  10   5   0   0 300 273 103  40  12  15 557]
max_step 26 num_step 9
reward 0
(48,) 0 False {}
cur_obs [ 31   3   5   0   0 330 205 105  39  14  18 619]
max_step 26 num_step 10
reward 0
(48,) 0 False {}
cur_obs [ 35   4   9   0   0 360 134 112  48  10  24 672]
max_step 26 num_step 11
reward 0
(48,) 0 False {}
cur_obs [ 28  12   5   0   0 390  93  88  45   5  26 743]
max_step 26 num_step 12
reward 0
(48,) 0 False {}
cur_obs [ 14  12   6   0   0 420  48  88  32   0  26 806]
max_step 26 num_step 13
reward 0
(48,) 0 False {}
cur_obs [  9   2   8   0   0 450  30  61  19   7  20 863]
max_step 26 num_step 14
reward 0
(48,) 0 False {}
cur_obs [  7   3   3   0   0 480  11  44  13   8  17 907]
max_step 26 num_step 15
reward 0
(48,) 0 False {}
cur_obs [  5   4   4   0   0 510   5  24  13   2  12 944]
max_step 26 num_step 16
reward 0
(48,) 0 False {}
cur_obs [  3   0   2   0   0 540   2  20   5   1  11 961]
max_step 26 num_step 17
reward 0
(48,) 0 False {}
cur_obs [  2   0   1   0   0 570   1   7   3   2   6 981]
max_step 26 num_step 18
reward 0
(48,) 0 False {}
cur_obs [  0   1   0   0   0 600   0   3   1   0   7 989]
max_step 26 num_step 19
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 630   0   2   0   0   6 992]
max_step 26 num_step 20
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 660   0   0   0   0   6 994]
max_step 26 num_step 21
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 690   0   0   0   0   6 994]
max_step 26 num_step 22
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 720   0   0   0   0   6 994]
max_step 26 num_step 23
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 750   0   0   0   0   6 994]
max_step 26 num_step 24
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 780   0   0   0   0   6 994]
max_step 26 num_step 25
reward 0
(48,) 0 True {'episode': {'r': 0}, 'events': [], 'env_id': 1}
reset
reset
cur_obs [  0   2   0  30   0  30 833 117  32  13   2   3]
max_step 26 num_step 0
reward 0
(48,) 0 False {}
cur_obs [  0   2  12  34  19  60 714 140  67  48   1  30]
max_step 26 num_step 1
reward 0
(48,) 0 False {}
cur_obs [  0   0  18  49  35  90 625 128 102  25  14 106]
max_step 26 num_step 2
reward 0
(48,) 0 False {}
cur_obs [ 54   3   8   0   0 120 570 149  65  16   1 199]
max_step 26 num_step 3
reward 0
(48,) 0 False {}
cur_obs [ 55  12   3   0   0 150 535  99  70  15   7 274]
max_step 26 num_step 4
reward 0
(48,) 0 False {}
cur_obs [ 47   6   5   0   0 180 496  80  58   7   9 350]
max_step 26 num_step 5
reward 0
(48,) 0 False {}
cur_obs [ 31  14   6   0   0 210 454  73  51   0  16 406]
max_step 26 num_step 6
reward 0
(48,) 0 False {}
cur_obs [ 22   3   8   0   0 240 410  75  33  13  15 454]
max_step 26 num_step 7
reward 0
(48,) 0 False {}
cur_obs [ 17   7   7   0   0 270 351  87  31  10  13 508]
max_step 26 num_step 8
reward 0
(48,) 0 False {}
cur_obs [ 23  19   5   0   0 300 273  88  47  16  17 559]
max_step 26 num_step 9
reward 0
(48,) 0 False {}
cur_obs [ 38   2   5   0   0 330 205 106  45  10  18 616]
max_step 26 num_step 10
reward 0
(48,) 0 False {}
cur_obs [ 36   9   5   0   0 360 134 109  50  12  20 675]
max_step 26 num_step 11
reward 0
(48,) 0 False {}
cur_obs [ 29  11   2   0   0 390  93  88  42  12  25 740]
max_step 26 num_step 12
reward 0
(48,) 0 False {}
cur_obs [  9  12   3   0   0 420  48  96  24   0  27 805]
max_step 26 num_step 13
reward 0
(48,) 0 False {}
cur_obs [  9   2   3   0   0 450  30  70  14   6  17 863]
max_step 26 num_step 14
reward 0
(48,) 0 False {}
cur_obs [  5   2   2   0   0 480  11  53   9   6  18 903]
max_step 26 num_step 15
reward 0
(48,) 0 False {}
cur_obs [  3   5   6   0   0 510   5  21  14   3  16 941]
max_step 26 num_step 16
reward 0
(48,) 0 False {}
cur_obs [  0   0   1   0   0 540   2  20   1   2  10 965]
max_step 26 num_step 17
reward 0
(48,) 0 False {}
cur_obs [  2   0   2   0   0 570   1  10   4   1   5 979]
max_step 26 num_step 18
reward 0
(48,) 0 False {}
cur_obs [  0   1   0   0   0 600   0   5   1   0   6 988]
max_step 26 num_step 19
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 630   0   1   0   0   6 993]
max_step 26 num_step 20
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 660   0   0   0   0   6 994]
max_step 26 num_step 21
reward 0
(48,) 0 False {}
cur_obs [  0   0   0   0   0 690   0   0   0   0   6 994]
max_step 26 num_step 22
reward 0
(48,) 0<configparser.ConfigParser object at 0x7fe2af2d4130>
step 0
reward(train) tensor([[0.],
        [0.]])
0.0 0 0.0 0.0
step 1
reward(train) tensor([[0.],
        [0.]])
0.0 1 0.0 0.0
step 2
reward(train) tensor([[0.],
        [0.]])
0.0 2 0.0 0.0
step 3
reward(train) tensor([[0.],
        [0.]])
0.0 3 0.0 0.0
step 4
reward(train) tensor([[0.],
        [0.]])
0.0 4 0.0 0.0
step 5
reward(train) tensor([[0.],
        [0.]])
0.0 5 0.0 0.0
step 6
reward(train) tensor([[0.],
        [0.]])
0.0 6 0.0 0.0
step 7
reward(train) tensor([[0.],
        [0.]])
0.0 7 0.0 0.0
step 8
reward(train) tensor([[0.],
        [0.]])
0.0 8 0.0 0.0
step 9
reward(train) tensor([[0.],
        [0.]])
0.0 9 0.0 0.0
step 10
reward(train) tensor([[0.],
        [0.]])
0.0 10 0.0 0.0
step 11
reward(train) tensor([[0.],
        [0.]])
0.0 11 0.0 0.0
step 12
reward(train) tensor([[0.],
        [0.]])
0.0 12 0.0 0.0
step 13
reward(train) tensor([[0.],
        [0.]])
0.0 13 0.0 0.0
step 14
reward(train) tensor([[0.],
        [0.]])
0.0 14 0.0 0.0
step 15
reward(train) tensor([[0.],
        [0.]])
0.0 15 0.0 0.0
step 16
reward(train) tensor([[0.],
        [0.]])
0.0 16 0.0 0.0
step 17
reward(train) tensor([[0.],
        [0.]])
0.0 17 0.0 0.0
step 18
reward(train) tensor([[0.],
        [0.]])
0.0 18 0.0 0.0
step 19
reward(train) tensor([[0.],
        [0.]])
0.0 19 0.0 0.0
step 20
reward(train) tensor([[0.],
        [0.]])
0.0 20 0.0 0.0
step 21
reward(train) tensor([[0.],
        [0.]])
0.0 21 0.0 0.0
step 22
reward(train) tensor([[0.],
        [0.]])
0.0 22 0.0 0.0
step 23
reward(train) tensor([[0.],
        [0.]])
0.0 23 0.0 0.0
step 24
reward(train) tensor([[0.],
        [0.]])
0.0 24 0.0 0.0
step 25
reward(train) tensor([[0.],
        [0.]])
0.0 0 0
0.0 1 0
1.0 25 0.0 0.0
value_loss 201.7113	action_loss 0.5328	entropy 0.2486	total_loss 101.3860
step 0
reward(train) tensor([[0.],
        [0.]])
1.0 0 0.0 0.0
step 1
reward(train) tensor([[0.],
        [0.]])
1.0 1 0.0 0.0
step 2
reward(train) tensor([[0.],
        [0.]])
1.0 2 0.0 0.0
step 3
reward(train) tensor([[0.],
        [0.]])
1.0 3 0.0 0.0
step 4
reward(train) tensor([[0.],
        [0.]])
1.0 4 0.0 0.0
step 5
reward(train) tensor([[0.],
        [0.]])
1.0 5 0.0 0.0
step 6
reward(train) tensor([[0.],
        [0.]])
1.0 6 0.0 0.0
step 7
reward(train) tensor([[0.],
        [0.]])
1.0 7 0.0 0.0
step 8
reward(train) tensor([[0.],
        [0.]])
1.0 8 0.0 0.0
step 9
reward(train) tensor([[0.],
        [0.]])
1.0 9 0.0 0.0
step 10
reward(train) tensor([[0.],
        [0.]])
1.0 10 0.0 0.0
step 11
reward(train) tensor([[0.],
        [0.]])
1.0 11 0.0 0.0
step 12
reward(train) tensor([[0.],
        [0.]])
1.0 12 0.0 0.0
step 13
reward(train) tensor([[0.],
        [0.]])
1.0 13 0.0 0.0
step 14
reward(train) tensor([[0.],
        [0.]])
1.0 14 0.0 0.0
step 15
reward(train) tensor([[0.],
        [0.]])
1.0 15 0.0 0.0
step 16
reward(train) tensor([[0.],
        [0.]])
1.0 16 0.0 0.0
step 17
reward(train) tensor([[0.],
        [0.]])
1.0 17 0.0 0.0
step 18
reward(train) tensor([[0.],
        [0.]])
1.0 18 0.0 0.0
step 19
reward(train) tensor([[0.],
        [0.]])
1.0 19 0.0 0.0
step 20
reward(train) tensor([[0.],
        [0.]])
1.0 20 0.0 0.0
step 21
reward(train) tensor([[0.],
        [0.]])
1.0 21 0.0 0.0
step 22
reward(train) tensor([[0.],
        [0.]])
1.0 22 0.0 0.0
step 23
reward(train) tensor([[0.],
        [0.]])
1.0 23 0.0 0.0
step 24
reward(train) tensor([[0.],
        [0.]])
1.0 24 0.0 0.0
step 25
reward(train) tensor([[0.],
        [0.]])
1.0 0 0
1.0 1 0
2.0 25 0.0 0.0
value_loss 46.5595	action_loss 0.1845	entropy 0.2755	total_loss 23.4615
step 0
reward(train) tensor([[0.],
        [0.]])
2.0 0 0.0 0.0
step 1
reward(train) tensor([[0.],
        [0.]])
2.0 1 0.0 0.0
step 2
reward(train) tensor([[0.],
        [0.]])
2.0 2 0.0 0.0
step 3
reward(train) tensor([[0.],
        [0.]])
2.0 3 0.0 0.0
step 4
reward(train) tensor([[0.],
        [0.]])
2.0 4 0.0 0.0
step 5
reward(train) tensor([[0.],
        [0.]])
2.0 5 0.0 0.0
step 6
reward(train) tensor([[0.],
        [0.]])
2.0 6 0.0 0.0
step 7
reward(train) tensor([[0.],
        [0.]])
2.0 7 0.0 0.0
step 8
reward(train) tensor([[0.],
        [0.]])
2.0 8 0.0 0.0
step 9
reward(train) tensor([[0.],
        [0.]])
2.0 9 0.0 0.0
step 10
reward(train) tensor([[0.],
        [0.]])
2.0 10 0.0 0.0
step 11
reward(train) tensor([[0.],
        [0.]])
2.0 11 0.0 0.0
step 12
reward(train) tensor([[0.],
        [0.]])
2.0 12 0.0 0.0
step 13
reward(train) tensor([[0.],
        [0.]])
2.0 13 0.0 0.0
step 14
reward(train) tensor([[0.],
        [0.]])
2.0 14 0.0 0.0
step 15
reward(train) tensor([[0.],
        [0.]])
2.0 15 0.0 0.0
step 16
reward(train) tensor([[0.],
        [0.]])
2.0 16 0.0 0.0
step 17
reward(train) tensor([[0.],
        [0.]])
2.0 17 0.0 0.0
step 18
reward(train) tensor([[0.],
        [0.]])
2.0 18 0.0 0.0
step 19
reward(train) tensor([[0.],
        [0.]])
2.0 19 0.0 0.0
step 20
reward(train) tensor([[0.],
        [0.]])
2.0 20 0.0 0.0
step 21
reward(train) tensor([[0.],
        [0.]])
2.0 21 0.0 0.0
step 22
reward(train) tensor([[0.],
        [0.]])
2.0 22 0.0 0.0
step 23
reward(train) tensor([[0.],
        [0.]])
2.0 23 0.0 0.0
step 24
reward(train) tensor([[0.],
        [0.]])
2.0 24 0.0 0.0
step 25
reward(train) tensor([[0.],
        [0.]])
2.0 0 0
2.0 1 0
3.0 25 0.0 0.0
value_loss 16.6602	action_loss -0.0200	entropy 0.2021	total_loss 8.3080
